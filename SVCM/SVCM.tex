% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Spatial Varying Coefficient Model},
  pdfauthor={Yewen Chen},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin = 0.5in]{geometry}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{bm,color,chngcntr,setspace,placeins,fancyhdr}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\onehalfspacing
\counterwithin{equation}{subsection}
\counterwithin{figure}{section}
\counterwithin{table}{section}
\pagestyle{fancy}

\title{Spatial Varying Coefficient Model}
\author{Yewen Chen}
\date{2019/6/22}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\Large
\newpage

\hypertarget{hierarchical-modeling-for-univariate-spatial-data}{%
\section{Hierarchical modeling for univariate spatial
data}\label{hierarchical-modeling-for-univariate-spatial-data}}

\hypertarget{model-framework}{%
\subsection{Model framework}\label{model-framework}}

Consider a simple linear model: \begin{equation}
   Y(s)=\mu(s)+\underbrace{w(s)+\varepsilon(s)}_{\eta(s)} \label{Eq:SVCM}
  \end{equation} where the mean structure \(\mu(s)=X(s)\bm{\beta}\), the
residual \(\eta(s)\) is partitioned into two pieces, one spatial and one
nonspatial.

Assumptions of model (\ref{Eq:SVCM}):

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(\varepsilon(s)\overset{i.i.d}{\sim} N(0,\tau^2);\)
\item
  \(\bm{w}\) is a stationary process independent of
  \(\bm{\varepsilon}\), and is a Gaussian processes(GP):
  \(\bm{w}\sim GP(\bm{0},\sigma^2\bm{H}(\phi))\), where
  \[(\bm{H}(\phi))_{ij}=\sigma^2\rho(\phi;\Vert s_i-s_j\Vert){\kern 14pt} i,j=1,2,\cdots,n.\]
\end{enumerate}

\hypertarget{model-decomposition}{%
\subsection{Model decomposition}\label{model-decomposition}}

There are two ways to fit model from Bayes's point of view:

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  \(p(\bm{\theta,w}|\bm{y})\propto f(\bm{y}|\bm{w},\bm{\beta},\tau^2)p(\bm{w}|\sigma^2,\phi)\pi(\bm{\theta})\)
\item
  \(p(\bm{\theta}|\bm{y})\propto f(\bm{y}|\bm{\theta})\pi(\bm{\theta})\)
\end{enumerate}

The structure of the model is so complex that
\textbf{numerical algorithm} is needed.

\hypertarget{model-solution}{%
\section{Model Solution}\label{model-solution}}

\hypertarget{mcmc-algorithm}{%
\subsection{MCMC algorithm}\label{mcmc-algorithm}}

Turn to (a), our goal is to sample
\(\boldsymbol{\theta}, \boldsymbol{w}\) from
\(p(\boldsymbol{\theta}, \boldsymbol{w} | \boldsymbol{y})\) based on
Gibbs sampler. Therefore, we need to solve
\(p\left(\boldsymbol{\beta} | \boldsymbol{y}, \boldsymbol{w}, \tau^{2}\right), p(\boldsymbol{w} | \boldsymbol{y}, \boldsymbol{\theta}), p\left(\tau^{2} | \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{\beta}, \boldsymbol{w}\right), p\left(\sigma^{2} | \boldsymbol{\phi}, \boldsymbol{w}\right)\)
and \(p\left(\phi | \boldsymbol{w}, \sigma^{2}\right).\)

\textbf{Step1}:
\(\operatorname{Set} \pi(\boldsymbol{\beta})=N\left(\boldsymbol{A} \boldsymbol{\alpha}, \boldsymbol{\Sigma}_{\boldsymbol{\beta}}\right),\)
then
\(p\left(\boldsymbol{\beta} | \boldsymbol{y}, \boldsymbol{w}, \tau^{2}\right)=N(\boldsymbol{D} \boldsymbol{\eta}, \boldsymbol{D}),\)
where \begin{equation}
\boldsymbol{D}=\left(\frac{\bm{X}^{\prime} \bm{X}}{\tau^{2}}+\boldsymbol{\Sigma}_{\beta}^{-1}\right)^{-1} ; \boldsymbol{\eta}=\frac{\boldsymbol{X}^{\prime}(\boldsymbol{y}-\boldsymbol{w})}{\tau^{2}}+\boldsymbol{\Sigma}_{\beta}^{-1} \boldsymbol{A} \boldsymbol{\alpha} \label{Eq:Post_Beta_Dis}
\end{equation}

\textbf{Step2}: Since
\(\pi(\boldsymbol{w})=N\left(0, \sigma^{2} \boldsymbol{H}(\phi)\right),\)
then \(p(\boldsymbol{w} | \boldsymbol{y}, \boldsymbol{\theta})\) is
again of the form
\(N(\boldsymbol{D} \boldsymbol{\eta}, \boldsymbol{D}),\) where
\begin{equation}
\boldsymbol{D}=\left(\frac{\boldsymbol{I}}{\tau^{2}}+\frac{\boldsymbol{H}^{-1}(\phi)}{\sigma^{2}}\right)^{-1} ; \boldsymbol{\eta}=\frac{(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta})}{\tau^{2}} \label{Eq:Post_W_Dis}
\end{equation}

\textbf{Step3}: Furthermore, set
\(\pi\left(\tau^{2}\right)=I G\left(a_{\tau}, b_{\tau}\right), \pi\left(\sigma^{2}\right)=I G\left(a_{\sigma}, b_{\sigma}\right),\)
respectively, then \begin{equation}
p\left(\tau^{2} | \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{\beta}, \boldsymbol{w}\right)=I G\left(a_{\tau}+\frac{n}{2}, b_{\tau}+\frac{(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})^{\prime}(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})}{2}\right)
\end{equation}

\begin{equation}
p\left(\sigma^{2} | \phi, \boldsymbol{w}\right)=I G\left(a_{\sigma}+\frac{n}{2}, b_{\sigma}+\frac{\boldsymbol{w}^{\prime} \boldsymbol{H}^{-1}(\phi) \boldsymbol{w}}{2}\right)
\end{equation}

\textbf{Step4}: However, no closed form is available for
\(p\left(\phi | \boldsymbol{w}, \sigma^{2}\right)\) as follow
\begin{equation}
p\left(\phi | \boldsymbol{w}, \sigma^{2}\right) \propto \pi(\phi) \exp \left(-\frac{\boldsymbol{w}^{\prime} \boldsymbol{H}^{-1}(\phi) \boldsymbol{w}}{2\sigma^2}\right)
\end{equation} Except \(\phi^{\prime}\) s sample, the other can be
sampled by Gibbs sampler, while the former can be taken by Metropolis
algorithm or slice sampling.

\hypertarget{variational-bayes}{%
\subsection{Variational Bayes}\label{variational-bayes}}

Give initial values to the expectation of
\(1 / \tau^{2}, \phi, \mathbf{w}\) and
\(\mathbf{R}(\phi)^{-1} : \mathbf{E}^{(0)}\left(1 / \tau^{2}\right)=\left(1 / \tau^{2}\right)^{(0)}, \mathbf{E}^{(0)}(\phi)=\phi^{(0)}, \bm{\mu}_{w}^{(0)}=\mathbf{0}\)
and
\(\mathbf{E}^{(0)}\left(\mathbf{R}(\phi)^{-1}\right)=\mathbf{R}\left(\phi^{(0)}\right)^{-1}.\)

\textbf{Step1}: Update the distribution of
\(\bm{\beta} \sim \operatorname{MVN}\left(\mu_{\beta}^{(t)}, \mathbf{V}_{\beta}^{(t)}\right),\)
where

\[\mathbf{V}_{\beta}^{(t)}=\left[\bm{E}^{(t-1)}\left(1 / \tau^{2}\right)\left(\mathbf{X}^{\prime} \mathbf{X}\right) + \Sigma_\beta^{- 1} \right]^{-1}\]
and
\[\bm{\mu}_{\beta}^{(t)}=\left[\bm{E}^{(t-1)}\left(1 / \tau^{2}\right)\left(\mathbf{X}^{\prime} \mathbf{X}\right) + \Sigma_\beta^{- 1} \right]^{-1} \left[\bm{E}^{(t-1)}\left(1 / \tau^{2}\right) \mathbf{X}^{\prime}\left(\mathbf{Y}-\boldsymbol{\mu}_{\mathbf{w}}^{(t-1)}\right) + \Sigma_\beta^{- 1}\right];\]

\textbf{Step2}: Update the distribution of \(\tau^{2} \sim I G\) with
parameters \(a_{\tau}+\frac{n}{2}\) and \[
b_{\tau}+\frac{1}{2}\left[\textbf{tr}\left(\mathbf{V}_{\mathbf{w}}^{(t-1)}\right)+p \mathrm{E}^{(t-1)}\left(1 / \tau^{2}\right)+\left(\mathbf{Y}-\boldsymbol{\mu}_{\mathbf{w}}^{(t-1)}\right)^{\prime}\left(\mathbf{I}_{n}-\mathbf{H}\right)\left(\mathbf{Y}-\boldsymbol{\mu}_{\mathbf{w}}^{(t-1)}\right)\right],\]
where
\(\mathbf{H}=\mathbf{X}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime}\),
calculate
\(m_{\tau^{2}}^{(t)}=\mathrm{E}^{(t)}\left(1 / \tau^{2}\right);\)

\textbf{Step3}: Update the distribution of \(\sigma^{2} \sim I G\) with
parameters \(a_{\sigma}+\frac{n}{2}\) and \[
b_{\sigma}+\frac{1}{2}\left\{\textbf{tr}\left[\mathrm{E}^{(t-1)}\left(\mathbf{R}(\phi)^{-1}\right) \mathbf{V}_{\mathbf{w}}^{(t-1)}\right]+ \bm{\mu}_{\mathbf{w}}^{(t-1)^{\prime}} \mathrm{E}^{(t-1)}\left(\mathbf{R}(\phi)^{-1}\right) \boldsymbol{\mu}_{\mathbf{w}}^{(t-1)}\right\};
\] calculate
\(m_{\sigma^{2}}^{(t)}=\mathrm{E}^{(t)}\left(1 / \sigma^{2}\right);\)

\textbf{Step4}: Update the distribution of
\(\mathbf{w} \sim \operatorname{MVN}\left(\mu_{\mathbf{w}}^{(t)}, \mathbf{V}_{\mathbf{w}}^{(t)}\right),\)
where \[
\mathbf{V}_{\mathbf{w}}^{(t)}=\left[m_{\sigma^{2}}^{(t)} \mathrm{E}^{(t-1)}\left(\mathbf{R}(\phi)^{-1}\right)+m_{\tau^{2}}^{(t)} \mathbf{I}_{n}\right]^{-1}
\] and \[
\boldsymbol{\mu}_{\mathbf{w}}^{(t)}=m_{\tau^{2}}^{(t)}\left[m_{\sigma^{2}}^{(t)} \mathrm{E}^{(t-1)}\left(\mathbf{R}(\phi)^{-1}\right)+m_{\tau^{2}}^{(t)} \mathbf{I}_{n}\right]^{-1}\left(\mathbf{Y}-\mathbf{X} \boldsymbol{\mu}_{\beta}^{(t)}\right)
\]

\textbf{Step5}: Update the distribution of \(\phi\) which is
proportional to \begin{equation}
g(\phi)=|\mathbf{R}(\phi)|^{-\frac{1}{2}} \exp \left\{-\frac{m_{\sigma^{2}}^{(t)}\left[\operatorname{tr}\left(\mathbf{R}(\phi)^{-1} \mathbf{V}_{\mathrm{w}}^{(t)}\right)+\boldsymbol{\mu}_{\mathrm{w}}^{(t)} \mathbf{R}(\phi)^{-1} \boldsymbol{\mu}_{\mathrm{w}}^{(t)}\right]}{2}\right\} \label{Eq:Phi_Function}
\end{equation} and calculate \(\mathrm{E}^{(t)}(\phi)\) and
\(\mathrm{E}^{(t)}\left(\mathbf{R}(\phi)^{-1}\right).\) However the
distribution function (\ref{Eq:Phi_Function}) is not analytically
tractable, so importance sampling is proposed to approximate.
\begin{equation}
\mathrm{E}(f(\phi))=\frac{\int f(\phi) g(\phi) \mathrm{d} \phi}{\int g(\phi) \mathrm{d} \phi}=\frac{\int f(\phi) \frac{g(\phi)}{p_{l}(\phi)} p_{I}(\phi) \mathrm{d} \phi}{\int \frac{g(\phi)}{p_{l}(\phi)} p_{I}(\phi) \mathrm{d} \phi} \approx \frac{\frac{1}{N} \sum_{i=1}^{N} f\left(\phi_{i}\right) W\left(\phi_{i}\right)}{\frac{1}{N} \sum_{i=1}^{N} W\left(\phi_{i}\right)}=\sum_{i=1}^{N} f\left(\phi_{i}\right) W^{*}\left(\phi_{i}\right) \label{Eq:IS}
\end{equation} where
\(\phi_{i} \stackrel{\text { iid }}{\sim} p_{I}(\phi), W\left(\phi_{i}\right)=g\left(\phi_{i}\right) / p_{I}\left(\phi_{i}\right)\)
and
\(W^{*}\left(\phi_{i}\right)=\frac{W\left(\phi_{i}\right)}{\sum_{i=1}^{N} W\left(\phi_{i}\right)}\).

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  Because the distributions of the parameters other than \(\phi\) only
  depend on \(\mathrm{E}\left(\mathbf{R}(\phi)^{-1}\right)\) using the
  expectation from importance sampling in (\ref{Eq:IS}) allows the
  \(\mathrm{VB}\) algorithm to proceed toward convergence.
\item
  After the \(\mathrm{VB}\) algorithm converges, importance sampling
  resampling method (Rubin, 1987) is used to simulate samples of
  \(\phi,\) which is proportional to (\ref{Eq:Phi_Function}). Inferences
  about \(p(\phi | \mathbf{Y})\) can be made based on these samples.
\end{enumerate}

\hypertarget{em-algorithm}{%
\subsection{EM algorithm}\label{em-algorithm}}

\textbf{E-step:} \[\begin{array}{l}
    Q(\bm{\theta}|\bm{\theta}^{(t)})=E_{\bm{w|y,\theta^{(t)}}}\left(\log p(\bm{y,w}|\bm{\theta})\right)\\
    {\kern 44pt}=E_{\bm{w|y,\theta^{(t)}}}\left(\log p(\bm{y}|\bm{w,\theta})p(\bm{w}|\sigma^2,\phi) \right)\\
    {\kern 44pt}=\underbrace{E_{\bm{w|y,\theta^{(t)}}}\left(\log   
     p(\bm{y}|\bm{w,\theta})\right)}_{Q_1}+\underbrace{E_{\bm{w|y,\theta^{(t)}}}\left(\log 
    p(\bm{w}|\sigma^2,\phi)\right)}_{Q_2}
  \end{array}\] where
\(p(\bm{y}|\bm{w,\theta})\sim N(\bm{X\beta-w},\tau^2\bm{I});p(\bm{w}|\sigma^2,\phi)\sim N(\bm{0},\sigma^2\bm{H}(\phi)).\)
Let \(E_{\bm{w|y,\theta^{(t)}}}(\cdot)=E(\cdot)\), then
\[Q_1=-\frac{n}{2}\log \tau^2-\frac{E_{\bm{w|y,\theta^{(t)}}}(\bm{y} - \bm{X\beta} - \bm{w})^\prime(\bm{y} - \bm{X\beta} - \bm{w})} {2\tau^2}\]
\[Q_2=-\frac{n}{2}\log \sigma^2-\frac{1}{2}\log |\bm{H}(\phi)|-\frac{E[\bm{w^\prime}\bm{H}^{-1}(\phi)\bm{w}]}{2\sigma^2}.\]

\textbf{M-step:} Therefore, to maximize \(Q_1\) and \(Q_2\) and then
obtain \begin{equation}
     \hat{\tau}^2=\frac{(\bm{y} - \bm{X\beta})^\prime(\bm{y} - \bm{X\beta})-2(\bm{y} - \bm{X\beta})^\prime     
                  E(\bm{w}) + E(\bm{w^\prime w})}{n}
  \end{equation} \begin{equation}
    \hat{\sigma}^2=\frac{E[\bm{w^\prime}\bm{H}^{-1}(\phi)\bm{w}]}{n}
  \end{equation} \begin{equation}
     \hat{\bm{\beta}}=(\bm{X}^\prime \bm{X})^{- 1}\bm{X}^\prime (\bm{y} - E(\bm{w}))
  \end{equation} \begin{equation}
  \phi_{k + 1} = \phi_{k} - \frac{\partial \bm{Q}_2/\partial \phi |_{\phi =  \phi_k}}{\partial^2 \bm{Q}_2/\partial \phi^2 |_{\phi = \phi_k}}
\end{equation}

where \[
E\left[\boldsymbol{w}^{\prime} \boldsymbol{w}\right]= \textbf{tr}(\bm{D}) + (\bm{D\eta})^\prime \bm{D\eta};
\] \[
\begin{aligned} E\left[\boldsymbol{w}^{\prime} \boldsymbol{H}^{-1}(\phi) \boldsymbol{w}\right] 
&= \textbf{tr}\left( \boldsymbol{H}^{-1}(\phi) E\left[ \boldsymbol{w}\boldsymbol{w}^{\prime} \right]\right)\\
&= \textbf{tr}\left( \boldsymbol{H}^{-1}(\phi) (\bm{D}  + \bm{D \eta\eta^\prime}\bm{D}^\prime)\right),
   \end{aligned}
\]see (\ref{Eq:Post_W_Dis}) for \(\bm{D}\) and \(\bm{\eta}.\) In
addition,
\begin{align} \frac{\partial \bm{Q}_2}{\partial \phi} &= -\frac{1}{2}\textbf{tr}\left( \bm{H}^{-1} \frac{\partial\bm{H}}{\partial\phi} \right) -\frac{1}{2\sigma^2} 
\textbf{tr}\left(\bm{H}^{-1}\frac{\partial \bm{H}}{\partial \phi}  \bm{H}^{-1}(\bm{D}  + \bm{D \eta\eta^\prime}\bm{D}^\prime) \right)
\end{align} \begin{equation}
\begin{aligned} \frac{\partial^{2} \boldsymbol{Q}_{2}}{\partial \phi^{2}}=&-\frac{1}{2} \textbf{tr}\left(\boldsymbol{H}^{-1} \frac{\partial \boldsymbol{H}}{\partial \phi} \boldsymbol{H}^{-1} \frac{\partial \boldsymbol{H}}{\partial \phi}\right)-\frac{1}{2} \textbf{tr}\left(\boldsymbol{H}^{-1} \frac{\partial^{2} \boldsymbol{H}}{\partial \phi^{2}}\right) \\ &-\frac{1}{2\sigma^2} \textbf{tr}\left(\boldsymbol{H}^{-1} \frac{\partial^{2} \boldsymbol{H}}{\partial \phi^{2}} \boldsymbol{H}^{-1}\left(\boldsymbol{D}+\boldsymbol{D} \boldsymbol{\eta} \boldsymbol{\eta}^{\prime} \boldsymbol{D}^{\prime}\right)\right) \\ & + \frac{1}{\sigma^2}\textbf{tr}\left(\boldsymbol{H}^{-1} \frac{\partial \boldsymbol{H}}{\partial \phi} \boldsymbol{H}^{-1} \frac{\partial \boldsymbol{H}}{\partial \phi} \boldsymbol{H}^{-1}\left(\boldsymbol{D}+\boldsymbol{D} \boldsymbol{\eta} \boldsymbol{\eta}^{\prime} \boldsymbol{D}^{\prime}\right)\right) \end{aligned}
\end{equation} here,
\[\left(\frac{\partial \bm{H}}{\partial \phi}\right)_{ij} = [1 - I_0(|s_i - s_j|)]\textbf{exp}(- \phi |s_i - s_j|)(- |s_i - s_j|);\]
\[\left(\frac{\partial^2 \bm{H}}{\partial \phi^2}\right)_{ij} = [1 - I_0(|s_i - s_j|)]\textbf{exp}(- 2\phi |s_i - s_j|)(- |s_i - s_j|)^2,\]
\(I_0(|s_i - s_j|) = 1 \mbox{ if } |s_i - s_j| = 0, \mbox{ and } 0 \mbox{ otherwise}; i, j = 1,2,\cdots, n.\)

\hypertarget{accelerated-em-the-px-em-algorith}{%
\subsection{Accelerated EM: The PX-EM
Algorith}\label{accelerated-em-the-px-em-algorith}}

See Liu C, Rubin D B, Wu Y N(1998), we have

\textbf{E-step:}
\[Q_1=-\frac{n}{2}\log \tau^2-\frac{E_{\bm{w|y,\theta^{(t)}}}(\bm{y} - \bm{X\beta} - \alpha \bm{w})^\prime(\bm{y} - \bm{X\beta} - \alpha \bm{w})} {2\tau^2}\]
\[Q_2=-\frac{n}{2}\log \sigma^2-\frac{1}{2}\log |\bm{H}(\phi)|-\frac{\alpha^2E[\bm{w^\prime}\bm{H}^{-1}(\phi)\bm{w}]}{2\sigma^2}.\]

\textbf{M-step:} Therefore, to maximize \(Q_1\) and \(Q_2\) and then
obtain \begin{equation}
     \hat{\tau}^2=\frac{(\bm{y} - \bm{X\beta})^\prime(\bm{y} - \bm{X\beta})-2\alpha(\bm{y} -   \bm{X\beta})^\prime  E(\bm{w}) + \alpha^2 E(\bm{w^\prime w})}{n}
  \end{equation} \begin{equation}
    \hat{\sigma}^2=\frac{\alpha^2 E[\bm{w^\prime}\bm{H}^{-1}(\phi)\bm{w}]}{n}
  \end{equation} \begin{equation}
     \hat{\bm{\beta}}=(\bm{X}^\prime \bm{X})^{- 1}\bm{X}^\prime (\bm{y} - \alpha E(\bm{w}))
  \end{equation} \begin{equation}
     \hat{\alpha}=(\bm{y} - \bm{X\beta})^\prime E(\bm{w})/ E(\bm{w^\prime w})
  \end{equation}

\hypertarget{appendix-a}{%
\section{Appendix A}\label{appendix-a}}

\hypertarget{vb}{%
\subsection{VB}\label{vb}}

Because of \begin{equation}
p\left(\tau^{2} | \boldsymbol{y}, \boldsymbol{X}, \boldsymbol{\beta}, \boldsymbol{w}\right)=I G\left(a_{\tau}+\frac{n}{2}, b_{\tau}+\frac{(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})^{\prime}(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})}{2}\right),
\end{equation} hence, only need to consider the expectation of this
term,
\((\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})^{\prime}(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})\),
which is
\[\begin{aligned} E_{\beta,w}[(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})^{\prime}(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}-\boldsymbol{w})]
= &(\bm{y} - \bm{\mu}_w)^\prime(\bm{y} - \bm{\mu}_w) + \textbf{tr}(\bm{\Sigma}_w) -  \\
& 2(\bm{y} - \bm{\mu}_w)^\prime\bm{X}(\bm{X}^\prime\bm{X})^{-1}\bm{X}^\prime(\bm{y} - \bm{\mu}_w) + \\
& E_\beta(\bm{\beta}^\prime\bm{X}^\prime \bm{X}\bm{\beta})
\end{aligned}
\] here, \[
\begin{aligned}
  E_\beta(\bm{\beta}^\prime\bm{X}^\prime \bm{X}\bm{\beta}) &=  E_\beta[\textbf{tr}(\bm{\beta}^\prime\bm{X}^\prime \bm{X}\bm{\beta})]
= E_\beta[\textbf{tr}(\bm{X}\bm{\beta} \bm{\beta}^\prime\bm{X}^\prime )]\\
& = \textbf{tr}\{\bm{X}E_\beta[\bm{\beta} \bm{\beta}^\prime]\bm{X}^\prime \}\\
& = \textbf{tr}\{\bm{X} (\bm{V}_\beta + \bm{\mu}_\beta \bm{\mu}_\beta^\prime )\bm{X}^\prime \}
\end{aligned}
\] Especially,
\(E_\beta(\bm{\beta}^\prime\bm{X}^\prime \bm{X}\bm{\beta}) = pE(\frac{1}{\tau^2}) + (\bm{y} - \bm{\mu}_w)^\prime\bm{X}(\bm{X}^\prime\bm{X})^{-1}\bm{X}^\prime(\bm{y} - \bm{\mu}_w),\)
as \(\bm{\Sigma}_\beta = \bm{0}.\)

\hypertarget{data-fusion}{%
\section{Data fusion}\label{data-fusion}}

Let \(\{\phi_{ik};i = 1, 2, k = 1, 2, \cdots, r.\}\) be pre-specified
spatial basis functions, then we have\\
\begin{equation}
\begin{aligned}
 Z(s) = \left(
                \begin{array}{c}
                  {X\left(s\right)} \\
                  {Y\left(s\right)}
                \end{array}
        \right) =
        \left(
              \begin{array}{c}
                {W(s)} \\
                {W(s)}
              \end{array}
       \right) +
      \left(
              \begin{array}{cc}
                \sum_{k = 1}^{r}\phi_{k}(s)\eta_{k} \\
                 0
              \end{array}
      \right) +
       \left(
              \begin{array}{c}
                {\xi_1(s)} \\
                {\xi_2(s)}
              \end{array}
      \right)
\end{aligned}
\end{equation}

\end{document}
